---
title: Detecting Completion of LLM Streaming Responses
description: A robust vanilla JavaScript solution for detecting when streaming responses from Large Language Models have completed
publishDate: 2024-08-13T00:00:00Z
image: https://images.unsplash.com/photo-1643780668909-580822430155?q=80&w=2664&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D
category: Web Development
tags:
  - JavaScript
  - LLM
  - MutationObserver
  - Streaming
  - web development
metadata:
  canonical: https://fogel.dev/detecting_llm_streaming_completion
---

# Detecting Completion of LLM Streaming Responses: A Robust Vanilla JavaScript Solution

## Introduction

In the world of Large Language Model (LLM) integrations, streaming responses have become the norm, offering a more dynamic and engaging user experience. However, this advancement brings a unique challenge: how do we reliably detect when a streaming response has completed, especially when we need to perform actions based on the complete response?

While this challenge might seem straightforward at first glance, it becomes more complex when we consider the constraints of working without heavy frameworks or backend solutions. This is particularly relevant if you're using a library like HTMX, Hotwire, building a browser extensions, or find yourself in a situation where a lightweight, frontend-only solution is preferable.

## Understanding the Streaming Pattern

Before we dive into the proposed approach, it's important to understand a common pattern used in LLM streaming interfaces. Many implementations, including popular ones like ChatGPT, use a specific class (e.g. `streaming` or `result-streaming`) to indicate the status of the response:

1. When a new response starts streaming, a new DOM node is created with a 'streaming' class.
2. As the response continues to stream, content is added to this node.
3. Once the streaming is complete, the 'streaming' class is removed from the node.

This pattern provides a clear, DOM-based signal for the start and end of streaming, which we can leverage in our solution.

## The Challenge of Reliable Detection

The key challenge lies in creating a solution that can:

1. Detect when new response nodes are added to the DOM (which could happen at any time).
2. For each new node, watch for the removal of the 'streaming' class.
3. Perform an action exactly once when the streaming is complete.
4. Handle multiple simultaneous streaming responses without interference.

To address these requirements, we need a two-stage approach using the MutationObserver API.

Certainly. I'll refine the section, maintaining the tone while smoothing out the content and removing the emphasis on the scope of observation. Here's the revised version:

## The Crucial Role of the Two-Stage Approach

After breaking down our implementation, it's important to understand why we use a two-stage approach with separate observers, rather than a single MutationObserver. This design choice is crucial for the reliability and efficiency of our solution.

### Why Not Use a Single Observer?

You might wonder: "Why can't we just use one MutationObserver to watch for both new messages and the completion of streaming?" It's a valid question, and understanding the answer reveals key insights about how MutationObserver works and the challenges of LLM streaming responses.

1. **Granularity of Actions**: We need to perform specific actions (like capturing the full text) for each individual message when it completes streaming. A single observer would make it difficult to associate actions with specific messages.

2. **Timing of Disconnection**: We need to stop observing each message node once its streaming is complete. With a single observer, we can't selectively stop watching one node while continuing to watch for new messages.

3. **Preventing Duplicate Events**: This is a crucial point that deserves special attention. Let's explore it further.

### The Pitfall of Duplicate Events

When using a single MutationObserver approach, there's a significant risk of triggering duplicate events. This can happen if we don't properly manage when to stop observing a specific message node. Consider this scenario:

```javascript
// This approach could trigger duplicate events
const observer = new MutationObserver((mutations) => {
  for (let mutation of mutations) {
    if (hasAssistantAttribute(mutation.target) && !mutation.target.classList.contains('result-streaming')) {
      const text = mutation.target.innerText.trim();
      postMessage(text, 'assistant');
      // Notice: No observer.disconnect() here
    }
  }
});

observer.observe(document.body, { attributes: true, subtree: true });
```

In this case, the observer continues to watch for mutations even after the streaming is complete. This can lead to several issues:

1. **Multiple Triggers**: If any attribute of the observed node changes after streaming is complete (which is not uncommon in dynamic web applications), our logic would trigger again, potentially sending duplicate messages or making redundant API calls.

2. **Race Conditions**: In scenarios with rapid updates, we might process a message before it's fully complete, leading to partial data being sent.

3. **Performance Impact**: Continuously observing nodes that no longer need observation can impact performance, especially in chat-like interfaces where many messages accumulate over time.

### The Problem with Premature Disconnection

On the other hand, if we try to use a single observer and disconnect it after processing a message, we encounter a different set of problems:

```javascript
// This approach would NOT work correctly
const observer = new MutationObserver((mutations) => {
  for (let mutation of mutations) {
    if (hasAssistantAttribute(mutation.target)) {
      if (!mutation.target.classList.contains('result-streaming')) {
        const text = mutation.target.innerText.trim();
        postMessage(text, 'assistant');
        observer.disconnect(); // This is the problem!
      }
    }
  }
});

observer.observe(document.body, { attributes: true, subtree: true });
```

The issue here is that `observer.disconnect()` would stop the entire observation process. This means:

1. We'd miss any new assistant messages that appear after the first one completes.
2. If multiple messages are streaming simultaneously, we'd only process the first one to finish.

### The Two-Stage Solution

Our two-stage approach addresses these issues by using two types of observers:

1. A main observer that continuously watches for new messages.
2. Individual observers for each message that monitor for the completion of streaming.

This design allows us to:

- Continuously detect new messages as they appear in the DOM.
- Independently track and process each streaming message.
- Avoid duplicate event triggers by disconnecting individual message observers once streaming is complete.
- Handle multiple simultaneous streaming messages without interference.

By implementing this two-stage approach, we create a robust system that efficiently handles the dynamic nature of LLM interfaces, where new messages can appear at any time and multiple messages might be streaming simultaneously. It provides a clean solution to the challenges of both premature disconnection and the risk of duplicate event triggering, ensuring our interface remains responsive and accurate.

## Implementing the Two-Stage MutationObserver Solution

Our solution involves two types of observers working in concert:

1. A main observer that watches for new assistant messages.
2. Individual observers for each message that monitor for the completion of streaming.

Let's break down the implementation into its key components:

### Step 1: Identifying Assistant Messages

First, we need a reliable way to identify which nodes in the DOM represent assistant messages:

```javascript
const hasAssistantAttribute = (node) => {
  return node.nodeType === Node.ELEMENT_NODE && node.getAttribute('data-message-author-role') === 'assistant';
};
```

This function checks if a given DOM node represents an assistant message by looking for a specific attribute. This allows us to focus only on relevant nodes, improving the efficiency of our observation.

### Step 2: Observing Individual Assistant Messages

Next, we create a function to observe each assistant message for the completion of streaming:

```javascript
function observeForRemovalOfStreamingClass(node) {
  let isStreaming = true;

  const observer = new MutationObserver((mutations) => {
    for (let mutation of mutations) {
      if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
        const currentClasses = node.classList;
        if (!currentClasses.contains('result-streaming') && isStreaming) {
          isStreaming = false;
          const text = node.innerText.trim();
          postMessage(text, 'assistant');
          observer.disconnect();
        }
      }
    }
  });

  observer.observe(node, {
    attributes: true,
    attributeFilter: ['class'],
    subtree: true,
  });

  return observer;
}
```

This function creates a new MutationObserver for a specific assistant message node. It watches for changes to the `class` attribute, captures the complete message text when the `result-streaming` class is removed, and ensures the action is only performed once per message. After processing the message, it disconnects the observer to clean up resources.

### Step 3: Setting Up the Main Observer

Finally, we set up the main observer that watches for new assistant messages:

```javascript
function setupMutationObserver() {
  const observer = new MutationObserver((mutations) => {
    for (let mutation of mutations) {
      if (mutation.type === 'attributes') {
        // hasAssistantAttribute() identifies the attribute in question, like
        // node.getAttribute("data-message-author-role") === "assistant"
        if (hasAssistantAttribute(mutation.target)) {
          observeForRemovalOfStreamingClass(mutation.target);
        }
      }
    }
  });

  observer.observe(document.body, {
    attributes: true,
    attributeFilter: ['data-message-author-role', 'class'],
    subtree: true,
  });
}
```

This main observer watches the entire document body for attribute changes. When it detects a new node with the assistant attribute, it creates a new observer for that specific node. It continues to run, catching any new assistant messages that appear in the DOM.

## The Power of This Approach

This two-stage approach offers several advantages:

1. **Handling Multiple Simultaneous Responses**: By creating individual observers for each message, we can handle multiple streaming responses concurrently without interference.

2. **Flexibility**: The solution is not tied to specific timing or length of responses, relying instead on DOM changes. This makes it adaptable to various LLM behaviors.

3. **Lightweight and Non-Intrusive**: Implemented in vanilla JavaScript, this solution doesn't interfere with the normal operation of the LLM interface and doesn't require heavy frameworks.

4. **Precise Control**: We can perform actions on completed responses without risk of duplication or missing events.

## Advanced Considerations

While our solution is robust for most scenarios, there are some advanced considerations to keep in mind:

1. **Race Conditions**: In rare cases, the streaming might complete before we set up our individual observer. To handle this, consider checking the class immediately after setting up the observer.

2. **Performance Optimization**: For applications with a high volume of messages, implement a cleanup strategy to remove observers for old messages.

3. **Error Handling**: Implement error handling to manage unexpected DOM structures or changes gracefully.

4. **Customization**: The current solution assumes specific class names and attributes. Adjust these based on the particular LLM interface you're working with.

5. **Targeted Observation**: Consider observing only the chat message container instead of the entire document body to improve efficiency.

## Conclusion

The two-stage MutationObserver approach we've explored offers a robust solution to this problem, particularly for lightweight, frontend-only implementations.

A key advantage of this method is its ability to trigger side effects exactly once upon the completion of a streamed response. By using a main observer for new messages and individual observers for each streaming message, we avoid the pitfalls of both duplicate events and premature disconnection.

This approach not only solves the immediate challenge of detecting stream completion but also demonstrates broader principles of effective DOM manipulation in dynamic interfaces. As LLMs become more prevalent in web applications, such precise and reliable detection methods will be crucial for creating responsive and efficient user experiences.

## Further Reading

- [MDN Web Docs: MutationObserver](https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver)
