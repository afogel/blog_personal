---
title: Detecting Completion of LLM Streaming Responses
excerpt: A vanilla JavaScript solution for detecting when streaming responses from Large Language Models have completed
publishDate: 2024-08-13T00:00:00Z
image: https://images.unsplash.com/photo-1643780668909-580822430155?q=80&w=2664&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D
category: Web Development
tags:
  - JavaScript
  - LLM
  - MutationObserver
  - Streaming
  - web development
  - exactly-once message delivery
  - exactly-once events
metadata:
  canonical: 'https://fogel.dev/detecting_llm_streaming_completion'
---

# Detecting Completion of LLM Streaming Responses: A Vanilla JavaScript Solution

## Introduction

In the world of Large Language Model (LLM) integrations, streaming responses have become the norm, offering a more dynamic and engaging user experience. However, this advancement brings a unique challenge: how do we reliably detect when a streaming response has completed, especially when we need to perform actions based on the complete response?

While this challenge might seem straightforward at first glance, it becomes more complex when we consider the constraints of working without heavy frameworks or backend solutions. This is particularly relevant if you're using a library like HTMX, Hotwire, building a browser extensions, or find yourself in a situation where a lightweight, frontend-only solution is preferable.

## Understanding the Streaming Pattern

Before we dive into the proposed approach, it's important to understand a common pattern used in LLM streaming interfaces. Many implementations, including popular ones like ChatGPT, use a specific class (e.g. `streaming` or `result-streaming`) to indicate the status of the response:

1. When a new response starts streaming, a new DOM node is created with a 'streaming' class.
2. As the response continues to stream, content is added to this node.
3. Once the streaming is complete, the 'streaming' class is removed from the node.

This pattern provides a clear, DOM-based signal for the start and end of streaming, which we can leverage in our solution.

## The Challenge of Reliable Detection

The key challenge lies in creating a solution that can:

1. Detect when new response nodes are added to the DOM (which could happen at any time).
2. For each new node, watch for the removal of the 'streaming' class.
3. Perform an action exactly once when the streaming is complete.
4. Handle multiple simultaneous streaming responses without interference.

To address these requirements, we need a two-stage approach using the `MutationObserver` API.

## The Crucial Role of the Two-Stage Approach

After breaking down our implementation, it's important to understand why we use a two-stage approach with separate observers, rather than a single `MutationObserver`. This design choice is crucial for the reliability and efficiency of our solution.

### Why Not Use a Single Observer?

You might wonder: "Why can't we just use one `MutationObserver` to watch for both new messages and the completion of streaming?" It's a valid question, and understanding the answer reveals key insights about how `MutationObserver` works and the challenges of LLM streaming responses.

1. **Granularity of Actions**: We need to perform specific actions (like capturing the full text) for each individual message when it completes streaming. A single observer would make it difficult to associate actions with specific messages.

2. **Timing of Disconnection**: We need to stop observing each message node once its streaming is complete. With a single observer, we can't selectively stop watching one node while continuing to watch for new messages.

3. **Preventing Duplicate Events**: This is a crucial point that deserves special attention. Let's explore it further with two examples.

### The Problem with Premature Disconnection

To prevent duplicate events and unnecessary processing, we need to stop observing a message node once its streaming is complete. However, with a single observer, attempting to disconnect after processing a message leads to significant issues. Let's look at what happens when we try to disconnect the observer after processing a message:

```javascript
// This approach would NOT work correctly
const observer = new MutationObserver((mutations) => {
  for (let mutation of mutations) {
    if (hasAssistantAttribute(mutation.target)) {
      if (!mutation.target.classList.contains('result-streaming')) {
        const text = mutation.target.innerText.trim();
        postMessage(text, 'assistant');
        observer.disconnect(); // This is the problem!
      }
    }
  }
});

observer.observe(document.body, { attributes: true, subtree: true });
```

The issue here is that `observer.disconnect()` would stop the entire observation process. This means:

1. We'd miss any new assistant messages that appear after the first one completes.
2. If multiple messages are streaming simultaneously, we'd only process the first one to finish.

### The Pitfall of Duplicate Events

On the other hand, if we don't disconnect the observer at all in an attempt to keep watching for new messages, we risk triggering duplicate events. Consider this scenario:

```javascript
// This approach could trigger duplicate events
const observer = new MutationObserver((mutations) => {
  for (let mutation of mutations) {
    if (hasAssistantAttribute(mutation.target) && !mutation.target.classList.contains('result-streaming')) {
      const text = mutation.target.innerText.trim();
      postMessage(text, 'assistant');
      // Notice: No observer.disconnect() here
    }
  }
});

observer.observe(document.body, { attributes: true, subtree: true });
```

In this case, the observer continues to watch for mutations even after the streaming is complete. This can lead to several issues:

1. **Multiple Triggers**: If any attribute of the observed node changes after streaming is complete (which is not uncommon in dynamic web applications), our logic would trigger again, potentially sending duplicate messages or making redundant API calls.

2. **Race Conditions**: In scenarios with rapid updates, we might process a message before it's fully complete, leading to partial data being sent.

3. **Performance Impact**: Continuously observing nodes that no longer need observation can impact performance, especially in chat-like interfaces where many messages accumulate over time.

By using separate observers for detecting new messages and monitoring individual message streaming, we can avoid these pitfalls and create a more robust solution.

### The Two-Stage Solution

To address these issues, we can implement a two-stage approach using separate observers:

1. A main observer that continuously watches for new messages.
2. Individual observers for each message that monitor for the completion of streaming.

This design offers several advantages:

- It keeps an eye out for new messages at all times.
- It tracks each streaming message separately.
- It stops watching a message once it's done, avoiding repeat processing.

By implementing this two-stage approach, we create a robust system that efficiently handles the dynamic nature of these streaming interfaces. It provides a solution that addresses the challenges of premature disconnection while guaranteeing that any side effects triggered once the streamed response ends happen **exactly once** [^1].

## Implementing the Two-Stage `MutationObserver` Solution

Our solution involves two types of observers working in concert:

1. A main observer that watches for new assistant messages.
2. Individual observers for each message that monitor for the completion of streaming.

Let's break down the implementation into its key components:

### Step 1: Observing Individual Assistant Messages

First, we create a function to observe each assistant message for the completion of streaming:

```javascript
function observeForRemovalOfStreamingClass(node) {
  let isStreaming = true;

  const observer = new MutationObserver((mutations) => {
    for (let mutation of mutations) {
      if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
        const currentClasses = node.classList;
        if (!currentClasses.contains('result-streaming') && isStreaming) {
          isStreaming = false;
          const text = node.innerText.trim();
          postMessage(text, 'assistant');
          observer.disconnect();
        }
      }
    }
  });

  observer.observe(node, {
    attributes: true,
    attributeFilter: ['class'],
    subtree: true,
  });

  return observer;
}
```

This function creates a new `MutationObserver` for a specific assistant message node. It watches for changes to the `class` attribute, captures the complete message text when the `result-streaming` class is removed, and ensures the action is only performed once per message. After processing the message, it disconnects the observer to clean up resources.

### Step 2: Setting Up the Main Observer

Next, we set up the main observer that watches for new assistant messages:

```javascript
function setupMutationObserver() {
  const observer = new MutationObserver((mutations) => {
    for (let mutation of mutations) {
      if (mutation.type === 'attributes') {
        // hasAssistantAttribute() is a utility function 
        // identifying the attribute in question
        if (hasAssistantAttribute(mutation.target)) {
          observeForRemovalOfStreamingClass(mutation.target);
        }
      }
    }
  });

  observer.observe(document.body, {
    attributes: true,
    attributeFilter: ['data-message-author-role', 'class'],
    subtree: true,
  });
}
```

This main observer watches the entire document body for attribute changes. When it detects a new node with the assistant attribute, it creates a new observer for that specific node. It continues to run, catching any new assistant messages that appear in the DOM.

## The Power of This Approach

This two-stage approach offers two key advantages:

1. **Flexibility**: The solution is not tied to specific timing or length of responses, relying instead on DOM changes. This makes it adaptable to various LLM behaviors.

2. **Precise Control**: We can perform actions on completed responses without risk of duplication or missing events.

## Added Considerations

While our solution is robust for most scenarios, there are some added considerations to keep in mind:

1. **Performance Optimization**: For applications with a high volume of messages, implement a cleanup strategy to remove observers for old messages.

2. **Customization**: The current solution assumes specific class names and attributes. Adjust these based on the particular LLM interface you're working with.

3. **Targeted Observation**: Consider observing only the chat message container instead of the entire document body to improve efficiency.

## Conclusion

The two-stage MutationObserver approach we've explored solves a critical challenge in LLM streaming interfaces: ensuring exactly-once processing of completed responses. This solution:

1. Captures new messages as they appear
2. Monitors each message individually
3. Guarantees exactly-once processing of completed responses

This approach is crucial for scenarios where missing an event or processing it twice could lead to errors, such as triggering transactions or updating databases based on LLM responses.

By using separate observers for new messages and individual streaming messages, we've created a robust system that handles the dynamic nature of LLM interfaces while maintaining precise control over response processing.

While focused on LLM streaming, these principles of targeted observation and careful observer management can be valuable in various scenarios involving dynamic DOM changes, offering a blueprint for reliable event processing in complex web applications.

## Further Reading

- [MDN Web Docs: MutationObserver](https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver)

## References
[^1]: [Exactly Once Delivery](https://exactly-once.github.io/posts/exactly-once-delivery/)
